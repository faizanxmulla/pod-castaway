Is not just having this be like a video call. I mean, that's fine, it's cool, it feels like it's immersive, but you can do a video call on your phone. The thing that you can do in the metaverse that is different from what you can do on a phone is like doing stuff where you're physically there together and participating in things together. And we could play games like this. We could have meetings like this in the future. Once you mix once you get mixed reality and augmented reality, we could have codec avatars like this and go into a meeting and have some people physically there and have some people show up in this photorealistic form superimposed on the physical environment. I think that stuff like that is going to be super powerful. So we got to still build out all those kind of applications and the use cases around it. But I don't know, I think it's going to be a pretty wild next few years around this. I'm actually almost at a loss of words. This is just so incredible. This is truly incredible. I hope that people watching this can get a glimpse of how incredible it is. It really feels like we're in the same room. I guess there's an uncanny valley that seems to have been crossed here. It looks like you. Yeah. There's still a bunch of tuning that I think we'll want to do where different people emote to different extents. Right. So I think one of the big questions is when you smile, how wide is your smile and how wide do you want your smile to be? And I think getting that to be tuned on a per person basis is going to be one of the things that we're going to need to figure out. It's like, to what extent do you want to give people control over that? Some people might try to might prefer a version of themselves that's more emotive in their avatar than their actual face is. So, for example, I always get a lot of critique and shit for having a relatively stiff expression, but I might feel pretty happy, but just make a pretty small smile, maybe. For me, it's like I'd want to have my avatar really be able to better express how I'm feeling than how I can do physically. So I think that there's a question about how you want to tune that, but overall, yeah, we want to start from the baseline of capturing how people actually emote and express themselves. And I think the initial version of this has been pretty impressive. And like you said, I do think we're kind of beyond the uncanny valley here where it does feel like you it doesn't feel weird or anything like that. I mean, that's going to be the meme that the two most monotone people are in a metaverse together. But I think that actually makes it more difficult. The amazing thing here is that the subtleties of the expression of the eyes. People say I'm monotone and emotionless, but I'm not. Maybe my expression of emotion is more subtle, usually, like with the eyes. And that's one of the things I've noticed, is just how expressive the subtle movement of the corners of the eyes are in terms of displaying happiness or boredom or all that kind of stuff. I am curious to see just because I've never done one of these before, I've never done a podcast as one of these codec avatars. And I'm curious to see what people think of it because one of the issues that we've had in some of the VR and mixed reality work is it tends to feel a lot more profound when you're in it than the 2D videos capturing the experience. So I think that this one, because it's photorealistic, may look kind of as amazing in 2D for people watching it as it feels, I think, to be in it. But we've certainly had this issue where a lot of the other things just it's like you feel the sense of immersion when you're in it. That doesn't quite translate to a 2D screen. But I don't know, I'm curious to see what people think. Yeah, I'm curious to see if people could see that my heart is actually beating fast now. This is super interesting that such intimacy of conversation could be achieved remotely. I don't do remote podcasts for this reason. And this breaks all of that. This feels like just an incredible transition to something else, to the different kind of communication breaks all barriers, like geographic, physical barriers. Do you have a sense of timeline in terms of how many difficult things have to be solved to make this more accessible to scanning with a smartphone? Yeah, I think we'll probably roll this out progressively over time so it's not going to be like we roll it out in one day. Everyone has a codec avatar. We want to get more people scanned and into the system and then we want to start integrating it into each one of our apps. Right. Making it so that I think that for a lot of the work style things, productivity, I think that this is going to make a ton of sense and a lot of gaming.